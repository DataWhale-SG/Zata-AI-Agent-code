{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'llm': {'api_type': 'zhipuai',\n",
       "  'api_key': 'd87bb8dbfc854c3dbc3edea867ca033e.3qCM41HN3pR7XG4T',\n",
       "  'model': 'glm-4-flash',\n",
       "  'base_url': 'https://open.bigmodel.cn/api/paas/v4/chat/completions',\n",
       "  'repair_llm_output': True},\n",
       " 'embedding': {'api_type': 'zhipuai',\n",
       "  'api_key': 'd87bb8dbfc854c3dbc3edea867ca033e.3qCM41HN3pR7XG4T',\n",
       "  'base_url': 'https://open.bigmodel.cn/api/paas/v4/embeddings',\n",
       "  'model': 'embedding-2'},\n",
       " 'browser': {'engine': 'selenium', 'browser_type': 'chrome'}}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import yaml\n",
    "\n",
    "with open('config/config2.yaml', 'r') as file:\n",
    "    config = yaml.safe_load(file)\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI(\n",
    "    api_key=\"d87bb8dbfc854c3dbc3edea867ca033e.3qCM41HN3pR7XG4T\",\n",
    "    base_url=\"https://open.bigmodel.cn/api/paas/v4/\"\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# 加载环境变量\n",
    "load_dotenv()\n",
    "# 从环境变量中读取api_key\n",
    "\n",
    "from openai import OpenAI\n",
    "from datetime import datetime\n",
    "def zhipu_web_search_tool(query: str) -> str:\n",
    "    \"\"\"\n",
    "    使用智谱AI的GLM-4模型进行联网搜索，返回搜索结果的字符串。\n",
    "    \n",
    "    参数:\n",
    "    - query: 搜索关键词\n",
    "\n",
    "    返回:\n",
    "    - 搜索结果的字符串形式\n",
    "    \"\"\"\n",
    "    \n",
    "    with open('config/config2.yaml', 'r') as file:\n",
    "        config = yaml.safe_load(file)\n",
    "    config['llm']['api_key']\n",
    "    # 初始化客户端\n",
    "    client = OpenAI(\n",
    "        api_key=config['llm']['api_key'],\n",
    "        base_url=\"https://open.bigmodel.cn/api/paas/v4/\"\n",
    "    ) \n",
    "    success = False\n",
    "\n",
    "    # 获取当前日期\n",
    "    current_date = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "\n",
    "    print(\"current_date:\", current_date)\n",
    "    \n",
    "    # 设置工具\n",
    "    tools = [{\n",
    "        \"type\": \"web_search\",\n",
    "        \"web_search\": {\n",
    "            \"enable\": True,\n",
    "            \"search_result\": True\n",
    "        }\n",
    "    }]\n",
    "\n",
    "    # 系统提示模板，包含时间信息\n",
    "    system_prompt = f\"\"\"你是一个具备网络访问能力的智能助手，在适当情况下，优先使用网络信息（参考信息）来回答，\n",
    "    以确保用户得到最新、准确的帮助。当前日期是 {current_date}。\"\"\"\n",
    "        \n",
    "    # 构建消息\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": query}\n",
    "    ]\n",
    "        \n",
    "    # 调用API\n",
    "\t# 因为智谱返回的结果有时候没有web_search，所以我们可以让它反复生成，直到生成web_search为止\n",
    "    while success == False:\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"glm-4-flash\",\n",
    "            messages=messages,\n",
    "            tools=tools\n",
    "        )\n",
    "        try:\n",
    "            rst = response.web_search\n",
    "            success = True\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "    \n",
    "    # 返回结果\n",
    "    return rst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_date: 2025-02-19\n",
      "[{'content': '吴说获悉，Solana 宣布首届全球线上 AI 黑客松正式启动，将于 12 月 10 日至 23 日举行，奖金总额超 18.5 万美元，设立六大赛道聚焦 AI 代理开发及基础设施建设等创新领域。主赛道由 a16z crypto 和 Solana Foundation 支持，奖金最高 3 万美元，其余赛道涵盖 AI 基础设施、代币工具、自治聊天代理、Social/影响力者代理等，每个赛道由行业合作伙伴提供支持。参赛无需注册，作品提交将于 12 月 15 日开始。Solana 提供团队匹配、导师指导和资源支持，激励开发者构建基于 Solana 的 AI 创新应用。\\n（转自：吴说）', 'icon': '', 'link': 'https://finance.sina.com.cn/blockchain/roll/2024-12-11/doc-incyzzcx0976575.shtml', 'media': '新浪财经', 'refer': 'ref_1', 'title': 'Solana 宣布首届全球线上 AI 黑客松正式启动'}, {'content': '本文来自：SendAI 负责人 Yash Agarwal\\n编译Odaily星球日报\\n译者Azuma\\n编者按：由 SendAI 主办的 Solana AI 黑客松启动已有一定时日，但由于 AI 叙事的持续升温，社区对于相关项目的追捧热度丝毫不减。\\n链上分析研究机构 Pine Analytics 昨日曾统计表示，由该场黑客松参与项目创建或直接关联的代币已多达 65 个，总市值为 4.82 亿美元，平均市值为 750 万美元，市值中位数为 170 万美元；有 13 个代币的市值超过 1000 万美元， 42 个代币的市值超过 100 万美元。\\n然而，在社区情绪如此激昂的情况下，SendAI 创始人 Yash Agarwal 今日却发布了一篇长文抨击当前的炒作乱象 —— Yash 强调过去一周黑客松主页仅有 4 万次访问，但随随便便一个代币都能速通 5000 万市值SendAI 本想构建一个助推 Solana 生态 AI 发展的平台，但现在却成为了堕落者们的赌场”。在 Yash 来看，当前的泡沫会造成开发者趋向于盲目、短时，不利于 Solana AI 的长线发展，因此有必要指出一些荒谬的状况，否则不久之后行业就会看到一场大灾难”。\\n以下为 Yash 全文内容，由 Odaily 星球日报编译。\\n当我们启动这场黑客松时，我有一个简单的愿景 —— 让 Solana 成为 AI 区块链，并实现 10 倍增长。\\n我认为黑客松是实现这一目标的最佳可行途径，我们可以将所有人聚集在同一屋檐下，我个人也可以投资那些非常看好的 Crypto x AI Agent 项目。\\n在过去的 1 个月里，我可以说 Solana AI 黑客松不仅已打响了品牌，且已完全改变了 Solana 生态 AI Agent 的格局。在 15 天内完成 400 多个项目绝非易事，我和我的团队对于为 Solana AI 生态增加 5 - 10 亿美元的市值而做的贡献感到无比自豪。\\n当然了，当我们启动这场黑客松时就曾有预感，由于这种奇怪的 Crypto x AI Agent 模型，会有一些相关代币发行。如果开发者是在利用代币作为资本积累手段，目的仍是构建出色的产品，那完全没有问题。我们还精心设计了所有 8 个赛道（赞助商对此没有发言权），以鼓励真正有用的 AI Agent 。\\n但我们没想到，它会变成堕落者们的赌场”。为了让大家对数字有更清晰的概念，Solana AI 黑客松的项目主页在过去一周只有超过 4 万名访客，', 'icon': '', 'link': 'https://finance.sina.com.cn/blockchain/roll/2025-01-06/doc-ineczakc2664172.shtml', 'media': '新浪财经', 'refer': 'ref_2', 'title': 'Solana AI黑客松“金狗”不断，主办方疾呼开发者停手'}, {'content': '如今正值技术变革的重要时刻，为了让更多的开发者拥抱 AI浪潮，学习和参与 AI开发与应用，腾讯云联合全国知名高校、热门技术社区重磅发起「AI开发黑客松」，围绕AI开发展开编程挑战赛、技术训练营、线上直播等技术实践系列活动。\\n本期腾讯云 AI 代码助手编程挑战赛作为「AI 开发黑客松」系列活动之一，以用AI构造AI——打造属于个人的Copilot”为题，聚焦腾讯云AI辅助编程工具的实战能力。你将使用腾讯云AI代码助手的强大辅助编程能力，尝试结合大模型与对话组件搭建出一个AI对话机器人的网页。你可借助腾讯云AI代码助手的强大能力完成赛题编码与作品发布，了解如何在编码过程中进行代码学习、代码设计优化、代码单元测试，实现编码提速！\\n快来加入「AI 开发黑客松」腾讯云AI代码助手编程挑战赛，动手实践吧！\\n一、两大重磅奖项，众多丰厚奖励\\n本次编程挑战赛分设优秀编程作品奖”与优秀内容创作奖”两个奖项。不论你是有好的代码创意，还是能够输出优秀作品内容，都有机会在本次比赛中突出重围，收获大奖！\\n优秀编程作品奖\\n一等奖（1名）：12000元\\n二等奖（2名）：8000元\\n三等奖（3名）：2000元\\n优秀内容创作奖\\n创作大师奖（1名）：6000元\\n创作精英奖（2名）：2000元\\n创作能手奖（3名）：800元\\n创作新星奖（10名）：300元\\n除奖金外，你还有机会获得：\\n腾讯云AI代码助手专业版：针对优秀编程作品奖及优秀内容创作奖获奖者，每人奖励腾讯云AI代码助手专业版（一年期）。（如果同时获得优秀编程作品奖及优秀内容创作奖，不重复计算）\\n腾讯周边：符合要求的前80名作品提交者，每人一个腾讯公仔。\\n专业开发者活跃交流圈：开发者一起学习交流、前沿信息共享、创新合作等；\\n流量扶持：优秀作品将有可能获得CSDN官方的流量扶持，提升个人影响力；\\n行业大咖指导及技术经验分享：腾讯云资深专家的技术及经验分享，专业指导和专家答疑等。\\n二、创意无限，等你来战\\n1、参赛人员\\n面向全社会开放。高等院校在校生、科研单位工作者、企业人员等均可以报名参加。\\n2、时间安排\\n2024年12月1日-2025年1月17日：线上报名及作品提交\\n2025年1月17日-2025年1月20日：线上评审\\n2025年1月21日：结果公布\\n三、赛前公开课不要错过！\\n为了帮助大家更好地备战，我们贴心准备了线上赛前公开课，为大家讲解如何利用腾讯云AI代码助手进行辅助编程，帮助大家顺利通关，勇夺佳绩！', 'icon': '', 'link': 'https://blog.csdn.net/csdnstudent/article/details/144554007', 'media': 'CSDN博客', 'refer': 'ref_3', 'title': '超级「码」力大PK！腾讯云 AI 代码助手编程挑战赛等你来战'}, {'content': '一、背景介绍\\n首先介绍一下参加这次【 NVIDIA NIM 黑客松训练营】的背景。\\n本人是一名 11 年的互联网开发老鸟了，从 Web 后端开发，到全栈开发，再到后拉的物联网开发，以及目前的研发管理，10 多年一步步见证了互联网焕然一新的快速变革之路，也就是从去年开始接触 AIGC、AI Agent 等相关的一些技术，也几乎体验了国内主流的大多数 AI 产品（看我以前的博文就可以看到 22 年初就体验【华为云 ModelArts】并且撰写了当时体验的过程）\\n但是随着 23 年 AI 的迅速发展和崛起，既出现了非常多的广泛 AI 应用场景、也改变了不少行业的工作方式和发展方向，本来作为一个老程序员，内心其实对新技术还是有一点点排斥的，但是我也知道，AI 这个技术，特别是做互联网开发的人，根本躲不过去的。所以这两年我主要业余精力都有放在 AI 和 Web3 领域；今年年初换购了一个 M3 MacBook Pro 其实也是想更多的研究这两个方面的技术（不要让硬件拖我后腿）。\\n然后参加这次【 NVIDIA NIM 黑客松训练营】也是看到有技术群里在讨论这个活动，周末抽空关注了一下，感觉挺有意思，把错过了的之前直播视频回放也恶补了一下。恶补完成后，就迫不及待的拿到相关训练营资料就直接开干了。\\n好了，废话不多说了，直接进入详细的 WorkShop 环节。\\n二、活动介绍\\n首先活动的形式是纯线上，以训练营学习的方式，再到动手实践，期间提供了非常详细的学习资料，让初次接受 NVIDIA NIM 微服务产品的开发者能够少走很多弯路。\\n其次，在资料介绍中，也提供了比较丰富多样的AI场景及模型教程，这样可以覆盖大多数开发者想实现的AI场景。\\n大语言模型 Phi-3 LLMs\\n生成代码 Granite Code\\n生成文本向量 Generate Embeddings for Text Retrieval （agent-blueprints）\\n视觉语义分割ChangeNet\\n光学字符检测OCDRNet\\n统计图表理解deplot（agent-blueprints）\\n并且还提供了一个较为完整的案例。\\n基于NVIDIA NIM 平台的知识问答系统实验手册\\n总之，从训练营准备工作来说，已经非常全面了，这样的训练营可以覆盖大多数的开发者进行友好的体验。\\n为了活动的趣味性和丰富性，活动方还准备了丰厚的活动激励，可以说是深得人心了，这下不支持都不行了，话不多说，', 'icon': '', 'link': 'https://blog.csdn.net/Mr_Roki/article/details/143468266', 'media': 'CSDN博客', 'refer': 'ref_4', 'title': '【NVIDIA NIM 黑客松训练营】实现剧本杀 AI 策划官（手摸手教程）'}, {'content': '作者：赵甜怡\\n编辑：林炯佳\\n2024年7月的一个晚上，在杭州湖畔创研中心的一个封闭会堂中人头攒动。\\n台下，二百多名年轻黑客席地而坐，随意地三两交谈。在他们之中，有的是顶刊AI论文的作者，有的是独立开发者，还有的是知名创业者此刻，他们正在期待着比赛的开始。\\n突然，全场熄灯，舞台灯光聚焦台上。\\n即将上台的Ryan紧张不已。还在上高二的他马上要在二百多位精英人才的注视下发言。\\n但这次他并不是来展示自己的项目，而是作为活动的创始人为开幕式致辞：\\n欢迎大家来到AdventureX——属于中国年轻人的第一场黑客松！”Ryan说罢，台下掌声雷动。\\n黑客松最早可以追溯到20世纪60年代，黑客亚文化席卷了现在闻名天下的硅谷。\\n打破传统的创新精神与计算机的技术力量相结合，组成了早期硅谷文化的核心。苹果创始人乔布斯也深受其影响。\\n半个多世纪过去，创新的火焰以活动的形式照亮着越来越多有理想的年轻人。\\n活动的类型有很多，主要是由科技公司举办的商业黑客松，以及高校、社群、公益组织举办的技术黑客松。\\n自从ChatGPT打响了新一轮的人工智能竞赛之后，全球黑客松的数量显著增加，越来越多社区和公益组织开始筹办相关活动。\\nAdventureX逃逸计划就是其一。\\n活动主题的别出心裁、创始团队的亮眼背景、参赛者的精彩表现都让这场活动成为了中国科技创投史上一个里程碑式的存在。\\nRyan介绍道，AdventureX是一场为期五天的黑客松活动，希望让更多中国年轻人为改变世界而活。\\n在活动现场，参赛者们自行组队，以团队的方式进行72小时的高强度产品开发，完成从头脑风暴、原型设计到代码编写和项目展示的全过程。\\n表现优秀的团队将有机会直接获得来自企业代表的大额奖金，以及基金投资人的天使轮资金。\\n年轻活力是AdventureX的底色。Ryan也为活动定下了准入门槛：最大参加年龄为26岁。\\n苛刻的门槛仍吸引了1200余名优秀人才争先报名。让人惊讶的是，从最初的想法到活动开始，只有4个月的筹备时间，创始团队也大部分都是高中生和大学生。\\n他们究竟是如何完成这场出彩的活动？\\nPConline与AdventureX创始人Ryan展开了深入对话。\\n第一个投资人很重要。”Ryan在大洋彼岸，顶着12小时的时差分享道。\\nRyan的思路是找到第一个有名气的机构投资——在圈子内建立信用度（Credibility）——利用信用度做宣传（Marketing），吸引更多的参赛者——利用参赛者的资源反向说服投资。', 'icon': '', 'link': 'https://tech.ifeng.com/c/8fetq46KTs1', 'media': '凤凰网科技', 'refer': 'ref_5', 'title': '年薪百万招不到人，AI工程师都去哪了？'}]\n"
     ]
    }
   ],
   "source": [
    "rsp = zhipu_web_search_tool(\"最近三个月有哪些AI黑客松？\")\n",
    "print(rsp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "智谱搜索函数封装成metagpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import asyncio\n",
    "import json\n",
    "from concurrent import futures\n",
    "from typing import Literal, Optional\n",
    "from pydantic import BaseModel, ConfigDict\n",
    "class ZhipuAPIWrapper(BaseModel):\n",
    "    model_config = ConfigDict(arbitrary_types_allowed=True)\n",
    "\n",
    "    loop: Optional[asyncio.AbstractEventLoop] = None\n",
    "    executor: Optional[futures.Executor] = None\n",
    "\n",
    "    async def run(\n",
    "        self,\n",
    "        query: str,\n",
    "        max_results: int = 5,\n",
    "        as_string: bool = True,\n",
    "    ) -> str | list[dict]:\n",
    "        \"\"\"Return the results of a Zhipu search using the official Google API\n",
    "\n",
    "        Args:\n",
    "            query: The search query.\n",
    "            max_results: The number of results to return.\n",
    "            as_string: A boolean flag to determine the return type of the results. If True, the function will\n",
    "                return a formatted string with the search results. If False, it will return a list of dictionaries\n",
    "                containing detailed information about each search result.\n",
    "\n",
    "        Returns:\n",
    "            The results of the search.\n",
    "        \"\"\"\n",
    "        loop = self.loop or asyncio.get_event_loop()\n",
    "        future = loop.run_in_executor(\n",
    "            self.executor,\n",
    "            self._search_from_zhipu,\n",
    "            query,\n",
    "            max_results,\n",
    "        )\n",
    "        search_results = await future\n",
    "        if as_string:\n",
    "            return json.dumps(search_results, ensure_ascii=False)\n",
    "        return search_results\n",
    "\n",
    "    def _search_from_zhipu(self, query: str, max_results: int):\n",
    "        return [\n",
    "            {\"link\": i[\"link\"], \"snippet\": i[\"content\"], \"title\": i[\"title\"]}\n",
    "            for (_, i) in zip(range(max_results), zhipu_web_search_tool(query))\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_date: 2025-02-19\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "run_func = ZhipuAPIWrapper().run\n",
    "found = await run_func(\"上海最近三个月有哪些AI会议？\", max_results=3, as_string=False)\n",
    "print(len(found))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import asyncio\n",
    "from typing import Any, Callable, Optional, Union\n",
    "# from metagpt.logs import logger\n",
    "# from metagpt.config2 import config\n",
    "from pydantic import TypeAdapter, model_validator\n",
    "from metagpt.actions import Action\n",
    "from metagpt.tools.search_engine import SearchEngine\n",
    "from metagpt.utils.common import OutputParser\n",
    "from metagpt.utils.text import generate_prompt_chunk, reduce_message_length\n",
    "\n",
    "LANG_PROMPT = \"请用{language}回答.\"\n",
    "\n",
    "RESEARCH_BASE_SYSTEM = \"\"\"你是一个专注于批判性思维的人工智能研究助理。你的唯一目标是根据给定的文本，撰写出结构严谨、客观公正、广受好评且文笔优美的报告。\"\"\"\n",
    "\n",
    "SEARCH_TOPIC_PROMPT:str = \"\"\"你是一个研究助理，请你为你的研究课题{topic}提供最多2个必要的关键词用于网络搜索。你的回答必须是JSON格式，例如：[\"关键词1\", \"关键词2\"]。\"\"\"\n",
    "\n",
    "SUMMARIZE_SEARCH_PROMPT = \"\"\"### 要求\n",
    "与你的研究课题相关的关键词及搜索结果会在“搜索结果信息”部分显示。\n",
    "### 搜索结果信息\n",
    "{search_results}\n",
    "根据搜索结果，提供最多 {decomposition_nums} 个与你的研究课题相关的查询。\n",
    "请以以下JSON格式回应：[\"query1\", \"query2\", \"query3\", ...]。除了python的list形式的JSON格式不要输出任何其他内容。\n",
    "\"\"\"\n",
    "\n",
    "COLLECT_AND_RANKURLS_PROMPT = \"\"\"### 主题\n",
    "{topic}\n",
    "### 查询\n",
    "{query}\n",
    "### 在线搜索结果\n",
    "{results}\n",
    "### 要求\n",
    "请移除与查询或主题无关的搜索结果。\n",
    "然后，根据链接的可信度对剩余的搜索结果进行排序。\n",
    "如果两个结果的可信度相同，则根据相关性优先级排序。\n",
    "提供排序后结果的索引，采用JSON格式，例如 [0, 1, 3, 4, ...]，不包含其他文字。\n",
    "\"\"\"\n",
    "\n",
    "class CollectLinks(Action):\n",
    "    \"\"\"Action class to collect links from a search engine.\"\"\"\n",
    "\n",
    "    name: str = \"CollectLinks\"\n",
    "    i_context: Optional[str] = None\n",
    "    desc: str = \"Collect links from a search engine.\"\n",
    "    search_func: Optional[Any] = None\n",
    "    search_engine: Optional[SearchEngine] = None\n",
    "    rank_func: Optional[Callable[[list[str]], None]] = None\n",
    "\n",
    "    @model_validator(mode=\"after\")\n",
    "    def validate_engine_and_run_func(self):\n",
    "        if self.search_engine is None:\n",
    "            self.search_engine = SearchEngine.from_search_func(ZhipuAPIWrapper().run)\n",
    "        return self\n",
    "\n",
    "    async def run(\n",
    "        self,\n",
    "        topic: str,\n",
    "        decomposition_nums: int = 4,\n",
    "        url_per_query: int = 4,\n",
    "        system_text: str | None = None,\n",
    "    ) -> dict[str, list[str]]:\n",
    "        \"\"\"Run the action to collect links.\n",
    "\n",
    "        Args:\n",
    "            topic: The research topic.\n",
    "            decomposition_nums: The number of search questions to generate.\n",
    "            url_per_query: The number of URLs to collect per search question.\n",
    "            system_text: The system text.\n",
    "\n",
    "        Returns:\n",
    "            A dictionary containing the search questions as keys and the collected URLs as values.\n",
    "        \"\"\"\n",
    "        system_text = system_text if system_text else RESEARCH_TOPIC_SYSTEM.format(topic=topic)\n",
    "        keywords = await self._aask(SEARCH_TOPIC_PROMPT.format(topic=topic))\n",
    "        try:\n",
    "            keywords = OutputParser.extract_struct(keywords, list)\n",
    "            keywords = TypeAdapter(list[str]).validate_python(keywords)\n",
    "        except Exception as e:\n",
    "            logger.exception(f\"fail to get keywords related to the research topic '{topic}' for {e}\")\n",
    "            keywords = [topic]\n",
    "        results = await asyncio.gather(*(self.search_engine.run(i, as_string=False) for i in keywords))\n",
    "\n",
    "        def gen_msg():\n",
    "            while True:\n",
    "                search_results = \"\\n\".join(\n",
    "                    f\"#### Keyword: {i}\\n Search Result: {j}\\n\" for (i, j) in zip(keywords, results)\n",
    "                )\n",
    "                prompt = SUMMARIZE_SEARCH_PROMPT.format(\n",
    "                    decomposition_nums=decomposition_nums, search_results=search_results\n",
    "                )\n",
    "                yield prompt\n",
    "                remove = max(results, key=len)\n",
    "                remove.pop()\n",
    "                if len(remove) == 0:\n",
    "                    break\n",
    "\n",
    "        model_name = 'gpt-4'\n",
    "        prompt = reduce_message_length(gen_msg(), model_name, system_text, config.llm.max_token)\n",
    "        logger.debug(prompt)\n",
    "        queries = await self._aask(prompt, [system_text])\n",
    "        try:\n",
    "            queries = OutputParser.extract_struct(queries, list)\n",
    "            queries = TypeAdapter(list[str]).validate_python(queries)\n",
    "        except Exception as e:\n",
    "            logger.exception(f\"fail to break down the research question due to {e}\")\n",
    "            queries = keywords\n",
    "        ret = {}\n",
    "        for query in queries:\n",
    "            ret[query] = await self._search_and_rank_urls(topic, query, url_per_query)\n",
    "        return ret\n",
    "\n",
    "    async def _search_and_rank_urls(self, topic: str, query: str, num_results: int = 2) -> list[str]:\n",
    "        \"\"\"Search and rank URLs based on a query.\n",
    "\n",
    "        Args:\n",
    "            topic: The research topic.\n",
    "            query: The search query.\n",
    "            num_results: The number of URLs to collect.\n",
    "\n",
    "        Returns:\n",
    "            A list of ranked URLs.\n",
    "        \"\"\"\n",
    "        max_results = max(num_results * 2, 5)\n",
    "        results = await self.search_engine.run(query, max_results=max_results, as_string=False)\n",
    "        if len(results) == 0:\n",
    "            return []\n",
    "        _results = \"\\n\".join(f\"{i}: {j}\" for i, j in zip(range(max_results), results))\n",
    "        prompt = COLLECT_AND_RANKURLS_PROMPT.format(topic=topic, query=query, results=_results)\n",
    "        logger.debug(prompt)\n",
    "        indices = await self._aask(prompt)\n",
    "        try:\n",
    "            indices = OutputParser.extract_struct(indices, list)\n",
    "            assert all(isinstance(i, int) for i in indices)\n",
    "        except Exception as e:\n",
    "            logger.exception(f\"fail to rank results for {e}\")\n",
    "            indices = list(range(max_results))\n",
    "        results = [results[i] for i in indices]\n",
    "        if self.rank_func:\n",
    "            results = self.rank_func(results)\n",
    "        return [i[\"link\"] for i in results[:num_results]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unknown encoding gpt-4. Plugins found: ['tiktoken_ext.openai_public']",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# 假设 \"qwen2.5:7b\" 使用与 \"gpt-4\" 相同的编码器\u001b[39;00m\n\u001b[0;32m      4\u001b[0m encoding_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgpt-4\u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# 或者其他已知与 \"qwen2.5:7b\" 兼容的编码器名称\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m encoding \u001b[38;5;241m=\u001b[39m \u001b[43mtiktoken\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_encoding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mencoding_name\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\zata\\.conda\\envs\\aiagent\\lib\\site-packages\\tiktoken\\registry.py:68\u001b[0m, in \u001b[0;36mget_encoding\u001b[1;34m(encoding_name)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m ENCODING_CONSTRUCTORS \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     67\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m encoding_name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ENCODING_CONSTRUCTORS:\n\u001b[1;32m---> 68\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m     69\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnknown encoding \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mencoding_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Plugins found: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m_available_plugin_modules()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     70\u001b[0m     )\n\u001b[0;32m     72\u001b[0m constructor \u001b[38;5;241m=\u001b[39m ENCODING_CONSTRUCTORS[encoding_name]\n\u001b[0;32m     73\u001b[0m enc \u001b[38;5;241m=\u001b[39m Encoding(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconstructor())\n",
      "\u001b[1;31mValueError\u001b[0m: Unknown encoding gpt-4. Plugins found: ['tiktoken_ext.openai_public']"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "model_name = \"qwen2.5:7b\"\n",
    "# 假设 \"qwen2.5:7b\" 使用与 \"gpt-4\" 相同的编码器\n",
    "encoding_name = \"gpt-4\"  # 或者其他已知与 \"qwen2.5:7b\" 兼容的编码器名称\n",
    "encoding = tiktoken.get_encoding(encoding_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiagent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
